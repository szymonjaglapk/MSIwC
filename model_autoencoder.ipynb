{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8cb51b",
   "metadata": {},
   "source": [
    "### Wczytanie danych z preprocesingu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3c11f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      5\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/processed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_train_scaled.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test_scaled.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m y_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Studia/MSIwC/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studia/MSIwC/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studia/MSIwC/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/Studia/MSIwC/venv/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('data/processed')\n",
    "\n",
    "# Dane do trenowania autoencodera (tylko normalne próbki)\n",
    "X_train_autoencoder = pd.read_csv(data_dir / 'autoencoder_train_data.csv')\n",
    "\n",
    "# Dane testowe\n",
    "X_test = pd.read_csv(data_dir / 'X_test_scaled.csv')\n",
    "y_test = pd.read_csv(data_dir / 'y_test.csv')\n",
    "\n",
    "print(\"Wczytano obrobione zbiory\")\n",
    "print(f\"Kształt X_train_autoencoder (tylko normalne): {X_train_autoencoder.shape}\")\n",
    "print(f\"Kształt X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbc2ad",
   "metadata": {},
   "source": [
    "### Informacje o danych treningowych\n",
    "Plik `autoencoder_train_data.csv` zawiera tylko normalne próbki (klasa 0) przygotowane w preprocesingu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Liczba normalnych próbek treningowych: {len(X_train_autoencoder)}\")\n",
    "print(f\"Liczba cech: {X_train_autoencoder.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4fac8",
   "metadata": {},
   "source": [
    "### Budowa modelu Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afee1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_dim = X_train_autoencoder.shape[1]\n",
    "encoding_dim = 16  # Rozmiar warstwy ukrytej\n",
    "\n",
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(64, activation='relu')(encoder_input)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = layers.Dense(32, activation='relu')(encoded)\n",
    "decoded = layers.Dense(64, activation='relu')(decoded)\n",
    "decoder_output = layers.Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "# Model\n",
    "autoencoder = keras.Model(encoder_input, decoder_output)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "print(\"Model Autoencoder zbudowany.\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d920c",
   "metadata": {},
   "source": [
    "### Trenowanie autoencodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trenowanie modelu Autoencoder...\")\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    X_train_autoencoder, X_train_autoencoder,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nModel wytrenowany.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37774368",
   "metadata": {},
   "source": [
    "### Wizualizacja procesu uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Proces uczenia Autoencodera')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495466b9",
   "metadata": {},
   "source": [
    "### Obliczanie błędu rekonstrukcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rekonstrukcja danych treningowych (normalnych)\n",
    "X_train_pred = autoencoder.predict(X_train_autoencoder)\n",
    "train_reconstruction_error = np.mean(np.abs(X_train_autoencoder - X_train_pred), axis=1)\n",
    "\n",
    "# Rekonstrukcja danych testowych\n",
    "X_test_pred = autoencoder.predict(X_test)\n",
    "test_reconstruction_error = np.mean(np.abs(X_test - X_test_pred), axis=1)\n",
    "\n",
    "print(f\"Średni błąd rekonstrukcji (trening): {train_reconstruction_error.mean():.4f}\")\n",
    "print(f\"Średni błąd rekonstrukcji (test): {test_reconstruction_error.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc0680",
   "metadata": {},
   "source": [
    "### Wyznaczanie progu decyzyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f477b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Próg jako percentyl błędu rekonstrukcji na danych treningowych\n",
    "threshold = np.percentile(train_reconstruction_error, 95)\n",
    "print(f\"Próg decyzyjny (95 percentyl): {threshold:.4f}\")\n",
    "\n",
    "# Wizualizacja rozkładu błędów\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_reconstruction_error, bins=50, alpha=0.7, label='Normalne (trening)')\n",
    "plt.axvline(threshold, color='r', linestyle='--', label=f'Próg = {threshold:.4f}')\n",
    "plt.xlabel('Błąd rekonstrukcji')\n",
    "plt.ylabel('Liczba próbek')\n",
    "plt.title('Rozkład błędów - dane treningowe')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "normal_errors = test_reconstruction_error[y_test.values.ravel() == 0]\n",
    "anomaly_errors = test_reconstruction_error[y_test.values.ravel() == 1]\n",
    "plt.hist(normal_errors, bins=30, alpha=0.7, label='Normalne (test)', color='green')\n",
    "plt.hist(anomaly_errors, bins=30, alpha=0.7, label='Anomalie (test)', color='red')\n",
    "plt.axvline(threshold, color='black', linestyle='--', label=f'Próg = {threshold:.4f}')\n",
    "plt.xlabel('Błąd rekonstrukcji')\n",
    "plt.ylabel('Liczba próbek')\n",
    "plt.title('Rozkład błędów - dane testowe')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb0f90",
   "metadata": {},
   "source": [
    "### Ocena modelu i macierz pomyłek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edce842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# Predykcja: błąd > próg = anomalia (1), błąd <= próg = normalne (0)\n",
    "y_pred = (test_reconstruction_error > threshold).astype(int)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"⭐ Wynik F1-Macro: {f1_macro:.4f}\")\n",
    "print(\"---\\n\")\n",
    "\n",
    "print(\"Raport klasyfikacji:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Normalne', 'Anomalie']))\n",
    "print(\"---\\n\")\n",
    "\n",
    "# Macierz pomyłek\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_labels = [0, 1]\n",
    "\n",
    "print(\"Macierz Pomyłek (Confusion Matrix):\\n\", cm)\n",
    "\n",
    "# Wizualizacja macierzy pomyłek\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normalne', 'Anomalie'])\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title('Macierz Pomyłek - Autoencoder')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9aa144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
