{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pip install kagglehub pandas matplotlib seaborn scikit-learn",
   "id": "85bcde71ac885d15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "RAW_DATA_PATH = '../data/raw/'\n",
    "all_csv_files = glob.glob(os.path.join(RAW_DATA_PATH, \"*.csv\"))\n",
    "list_of_dfs = []\n",
    "\n",
    "for file_path in all_csv_files:\n",
    "    print(f\"Wczytywanie: {os.path.basename(file_path)}...\")\n",
    "    try:\n",
    "        df_temp = pd.read_csv(\n",
    "            file_path,\n",
    "            encoding='latin1',\n",
    "            low_memory=False\n",
    "        )\n",
    "        list_of_dfs.append(df_temp)\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd przy wczytywaniu {file_path}: {e}\")\n",
    "\n",
    "if not list_of_dfs:\n",
    "    print(\"Żaden plik nie został wczytany.\")\n",
    "else:\n",
    "    df_combined = pd.concat(list_of_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    print(\"\\n--- Pliki połączone ---\")\n",
    "\n",
    "    if ' Label' in df_combined.columns:\n",
    "        print(\"\\nRozkład etykiet w połączonym zbiorze:\")\n",
    "        print(df_combined[' Label'].value_counts())\n",
    "    else:\n",
    "        print(\"\\nUWAGA: Nie znaleziono kolumny ' Label'. Sprawdź nazwy kolumn.\")\n",
    "\n",
    "    print(\"\\nPierwsze 5 wierszy połączonych danych:\")\n",
    "    display(df_combined.head())"
   ],
   "id": "968983be48473532",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Oryginalny kształt danych (wiersze, kolumny): {df_combined.shape}\")\n",
    "original_rows = df_combined.shape[0]\n",
    "print(\"\\nTypy danych w kolumnach (fragment): ---\")\n",
    "print(df_combined.info(verbose=False))\n",
    "\n",
    "label_column = ' Label'\n",
    "\n",
    "if label_column in df_combined.columns:\n",
    "    print(f\"\\nRozkład klas (ataków i ruchu normalnego)\")\n",
    "    print(df_combined[label_column].value_counts())\n",
    "else:\n",
    "    print(f\"\\nBŁĄD: Nie znaleziono kolumny '{label_column}'\")\n",
    "\n",
    "print(\"\\nStatystyki opisowe (próbka):\")\n",
    "display(df_combined.describe())"
   ],
   "id": "64776d4419e3423c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = df_combined.copy()\n",
    "\n",
    "original_rows = df.shape[0]\n",
    "original_cols = df.shape[1]\n",
    "print(f\"Początkowy rozmiar danych: {df.shape}\")\n",
    "\n",
    "label_column = ' Label'\n",
    "target_labels = ['BENIGN', 'DoS Hulk', 'FTP-Patator']\n",
    "\n",
    "print(f\"\\nFiltrowanie do etykiet: {target_labels}...\")\n",
    "df = df[df[label_column].isin(target_labels)]\n",
    "print(f\"Rozmiar po filtrowaniu etykiet: {df.shape}\")\n",
    "\n",
    "print(\"\\nRozpoczynanie czyszczenia danych...\")\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "rows_before_na = df.shape[0]\n",
    "df.dropna(inplace=True)\n",
    "rows_after_na = df.shape[0]\n",
    "print(f\"Usunięto {rows_before_na - rows_after_na} wierszy z wartościami NaN lub Inf.\")\n",
    "\n",
    "rows_before_neg = df.shape[0]\n",
    "df = df[df[' Flow Duration'] >= 0]\n",
    "rows_after_neg = df.shape[0]\n",
    "print(f\"Usunięto {rows_before_neg - rows_after_neg} wierszy z ujemnym czasem trwania.\")\n",
    "\n",
    "rows_before_dup = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "rows_after_dup = df.shape[0]\n",
    "print(f\"Usunięto {rows_before_dup - rows_after_dup} zduplikowanych wierszy.\")\n",
    "final_rows_after_cleaning = df.shape[0]\n",
    "\n",
    "df['Binary_Label'] = df[label_column].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "df = df.drop(columns=[label_column])\n",
    "\n",
    "print(\"\\nRozpoczynanie redukcji wymiarowości...\")\n",
    "\n",
    "metadata_cols = ['Flow ID', ' Source IP', ' Destination IP', ' Timestamp', ' Destination Port']\n",
    "existing_metadata_cols = [col for col in metadata_cols if col in df.columns]\n",
    "df = df.drop(columns=existing_metadata_cols)\n",
    "print(f\"Usunięto {len(existing_metadata_cols)} kolumn z metadanymi.\")\n",
    "y = df['Binary_Label']\n",
    "X = df.drop(columns=['Binary_Label'])\n",
    "cols_before_const = X.shape[1]\n",
    "constant_cols = X.columns[X.nunique() == 1]\n",
    "X = X.drop(columns=constant_cols)\n",
    "cols_after_const = X.shape[1]\n",
    "print(f\"Usunięto {len(constant_cols)} stałych kolumn (np. 'Bwd PSH Flags').\")\n",
    "print(f\"Lista usuniętych stałych kolumn: {list(constant_cols)}\")\n",
    "\n",
    "final_cols_after_reduction = X.shape[1]\n",
    "\n",
    "print(\"\\nDzielenie na zbiory treningowe i testowe...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Zbiór treningowy: {X_train.shape[0]} próbek\")\n",
    "print(f\"Zbiór testowy:    {X_test.shape[0]} próbek\")\n",
    "print(\"\\nNormalizowanie danych (MinMaxScaler)...\")\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "print(\"Pre-processing zakończony\")"
   ],
   "id": "add487d9bb13e16b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\\nWYNIK: Próbka (pierwsze 5 wierszy) przetworzonych danych treningowych\")\n",
    "display(X_train_scaled.head())\n",
    "\n",
    "print(\"\\n\\nWYNIK: Statystyki przetworzonych danych (potwierdzenie normalizacji)\")\n",
    "display(X_train_scaled.describe())\n",
    "\n",
    "PROCESSED_DATA_PATH = '../data/processed'\n",
    "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
    "print(f\"Pliki zostaną zapisane w folderze: '{PROCESSED_DATA_PATH}/'\")\n",
    "\n",
    "X_train_scaled.to_csv(os.path.join(PROCESSED_DATA_PATH, \"X_train_scaled.csv\"), index=False)\n",
    "y_train.to_csv(os.path.join(PROCESSED_DATA_PATH, \"y_train.csv\"), index=False)\n",
    "\n",
    "X_test_scaled.to_csv(os.path.join(PROCESSED_DATA_PATH, \"X_test_scaled.csv\"), index=False)\n",
    "y_test.to_csv(os.path.join(PROCESSED_DATA_PATH, \"y_test.csv\"), index=False)\n",
    "\n",
    "print(\"Przygotowywanie danych dla autoenkodera (tylko ruch normalny)...\")\n",
    "\n",
    "train_data_scaled = X_train_scaled.copy()\n",
    "train_data_scaled['Binary_Label'] = y_train.values\n",
    "\n",
    "autoencoder_train_data = train_data_scaled[train_data_scaled['Binary_Label'] == 0]\n",
    "autoencoder_train_data = autoencoder_train_data.drop(columns=['Binary_Label'])\n",
    "\n",
    "autoencoder_train_data.to_csv(os.path.join(PROCESSED_DATA_PATH, \"autoencoder_train_data.csv\"), index=False)\n",
    "\n",
    "print(f\"Zapisano 'X_train_scaled.csv' i 'y_train.csv' w '{PROCESSED_DATA_PATH}'.\")\n",
    "print(f\"Zapisano 'X_test_scaled.csv' i 'y_test.csv' w '{PROCESSED_DATA_PATH}'.\")\n",
    "print(f\"Zapisano 'autoencoder_train_data.csv' w '{PROCESSED_DATA_PATH}'.\")"
   ],
   "id": "35976d46f9215dde",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
